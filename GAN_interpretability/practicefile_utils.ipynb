{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import errno\n",
    "import torchvision.utils as vutils\n",
    "from tensorboardX import SummaryWriter\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Logger:\n",
    "\n",
    "    def __init__(self, model_name, data_name):\n",
    "        self.model_name = model_name\n",
    "        self.data_name = data_name\n",
    "\n",
    "        self.comment = '{}_{}'.format(model_name, data_name)\n",
    "        self.data_subdir = '{}/{}'.format(model_name, data_name)\n",
    "\n",
    "        # TensorBoard\n",
    "        # SummaryWriter class is your main entry to log data for consumption and visualization\n",
    "        # by TensorBoard\n",
    "        self.writer = SummaryWriter(comment=self.comment)\n",
    "        \n",
    "        \n",
    "        # two important static methods\n",
    "        # important note: static method is linked to the class directly can be called or defined\n",
    "        # anywhere in the class \n",
    "        # this function calculates the step number\n",
    "        @staticmethod\n",
    "        def _step(epoch, n_batch, num_batches):\n",
    "            return epoch * num_batches + n_batch\n",
    "\n",
    "        # this function it creates directory per requirements\n",
    "        # important note: raise keyword is used to reraise the current exception \n",
    "        # in an exception handler, so that it can be handled further up the call stack.\n",
    "        @staticmethod\n",
    "        def _make_dir(directory):\n",
    "            try:\n",
    "                os.makedirs(directory)\n",
    "            except OSError as e:\n",
    "                if e.errno != errno.EEXIST:\n",
    "                    raise\n",
    "        \n",
    "        # function that writes two scalars associated with losses - for discriminator\n",
    "        # and generator \n",
    "        def log(self, d_error, g_error, epoch, n_batch, num_batches):\n",
    "\n",
    "            if isinstance(d_error, torch.autograd.Variable):\n",
    "                d_error = d_error.data.cpu().numpy()\n",
    "            if isinstance(g_error, torch.autograd.Variable):\n",
    "                g_error = g_error.data.cpu().numpy()\n",
    "\n",
    "            step = Logger._step(epoch, n_batch, num_batches)\n",
    "            # argument passed - data identifier, scalar_name, global_step_mnumber\n",
    "            self.writer.add_scalar('{}/D_error'.format(self.comment), d_error, step)\n",
    "            self.writer.add_scalar('{}/G_error'.format(self.comment), g_error, step)\n",
    "            \n",
    "    # this function is meant to transform the images to the desired format  \n",
    "    def log_images(self, images, num_images, epoch, n_batch, num_batches, format='NCHW', normalize=True):\n",
    "        '''\n",
    "        input images are expected in format (NCHW) Batch No., Channel, Height, Width\n",
    "        '''\n",
    "        # convert it to torch tensor\n",
    "        if type(images) == np.ndarray:\n",
    "            images = torch.from_numpy(images)\n",
    "        # get the desired image dimensions\n",
    "        if format=='NHWC':\n",
    "            images = images.transpose(1,3)\n",
    "        \n",
    "\n",
    "        step = Logger._step(epoch, n_batch, num_batches)\n",
    "        img_name = '{}/images{}'.format(self.comment, '_' + str(step))\n",
    "\n",
    "        # Make horizontal grid from image tensor, normalization is MinMaxScaling\n",
    "        # scale_each option if true would take min and max value for the individual image rather than \n",
    "        # the entire batch of images \n",
    "        horizontal_grid = vutils.make_grid(images, normalize=normalize, scale_each=True)\n",
    "        # Make vertical grid from image tensor, normalization is MinMaxScaling\n",
    "        nrows = int(np.sqrt(num_images))\n",
    "        grid = vutils.make_grid(images, nrow=nrows, normalize=True, scale_each=True)\n",
    "\n",
    "        # Add horizontal images to tensorboard\n",
    "        # format would be tag_name, tensor to be displayed, global_step_number\n",
    "        self.writer.add_image(img_name, horizontal_grid, step)\n",
    "\n",
    "        # Save plots\n",
    "        self.save_torch_images(horizontal_grid, grid, epoch, n_batch)\n",
    "        \n",
    "    # this function saves a given matplotlib figure passed using fig argument\n",
    "    def _save_images(self, fig, epoch, n_batch, comment=''):\n",
    "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
    "        Logger._make_dir(out_dir)\n",
    "        # finally save the images\n",
    "        fig.savefig('{}/{}_epoch_{}_batch_{}.png'.format(out_dir,comment, epoch, n_batch))\n",
    "        \n",
    "    # saving the two versions of the image grids \n",
    "    def save_torch_images(self, horizontal_grid, grid, epoch, n_batch, plot_horizontal=True):\n",
    "        out_dir = './data/images/{}'.format(self.data_subdir)\n",
    "        Logger._make_dir(out_dir)\n",
    "\n",
    "        # Plot and save horizontal\n",
    "        fig = plt.figure(figsize=(16, 16))\n",
    "        plt.imshow(np.moveaxis(horizontal_grid.numpy(), 0, -1))\n",
    "        plt.axis('off')\n",
    "        if plot_horizontal:\n",
    "            # get the current figure\n",
    "            display.display(plt.gcf())\n",
    "        self._save_images(fig, epoch, n_batch, 'hori')\n",
    "        plt.close()\n",
    "\n",
    "        # Save squared\n",
    "        fig = plt.figure()\n",
    "        plt.imshow(np.moveaxis(grid.numpy(), 0, -1))\n",
    "        plt.axis('off')\n",
    "        self._save_images(fig, epoch, n_batch)\n",
    "        plt.close()\n",
    "    \n",
    "    # function to display the current status of the losses, prediction probs \n",
    "    def display_status(self, epoch, num_epochs, n_batch, num_batches, d_error, g_error, d_pred_real, d_pred_fake):\n",
    "        \n",
    " \n",
    "        if isinstance(d_error, torch.autograd.Variable):\n",
    "            d_error = d_error.data.cpu().numpy()\n",
    "        if isinstance(g_error, torch.autograd.Variable):\n",
    "            g_error = g_error.data.cpu().numpy()\n",
    "        if isinstance(d_pred_real, torch.autograd.Variable):\n",
    "            d_pred_real = d_pred_real.data\n",
    "        if isinstance(d_pred_fake, torch.autograd.Variable):\n",
    "            d_pred_fake = d_pred_fake.data\n",
    "        \n",
    "        \n",
    "        print('Epoch: [{}/{}], Batch Num: [{}/{}]'.format(epoch,num_epochs, n_batch, num_batches))\n",
    "        print('Discriminator Loss: {:.4f}, Generator Loss: {:.4f}'.format(d_error, g_error))\n",
    "        print('D(x): {:.4f}, D(G(z)): {:.4f}'.format(d_pred_real.mean(), d_pred_fake.mean()))\n",
    "\n",
    "    \n",
    "    # saving the model state after each epoch\n",
    "    def save_models(self, generator, discriminator, epoch):\n",
    "        out_dir = './data/models/{}'.format(self.data_subdir)\n",
    "        Logger._make_dir(out_dir)\n",
    "        torch.save(generator.state_dict(),'{}/G_epoch_{}'.format(out_dir, epoch))\n",
    "        torch.save(discriminator.state_dict(),'{}/D_epoch_{}'.format(out_dir, epoch))\n",
    "\n",
    "    # function is for closing the writer\n",
    "    def close(self):\n",
    "        self.writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name is VGan for Vanilla GAN\n",
    "# data_name is MNIST\n",
    "test = Logger(\"VGan\",\"MNIST\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VGan'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MNIST'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.data_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VGan_MNIST'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.comment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'VGan/MNIST'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.data_subdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how does class method work\n",
    "\n",
    "class Employee:\n",
    "    \n",
    "    def __init__(self, first, last, income):\n",
    "        self.first = first\n",
    "        self.last = last\n",
    "        self.income = income\n",
    "        \n",
    "    def annual_pay(self):\n",
    "        return self.income * 12\n",
    "    \n",
    "    @classmethod\n",
    "    def from_string_hyphen(cls, emp_str):\n",
    "        first, last, income = emp_str.split('-')\n",
    "        return cls(first, last,int(income))\n",
    "    \n",
    "    @staticmethod\n",
    "    def is_workday(day):\n",
    "        if day.weekday()==5 or day.weekday()==6:\n",
    "            return False\n",
    "        else: \n",
    "            return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_1 = Employee('Ramya','Balasubramaniam',30000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ramya'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_1.first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Balasubramaniam'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_1.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_1.income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360000"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_1.annual_pay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "emp_2 = Employee.from_string_hyphen('Girish-Kumar-30000')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Girish'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_2.first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kumar'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_2.last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_2.income"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "360000"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_2.annual_pay()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_date = datetime.date(2016,7,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emp_1.is_workday(my_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
